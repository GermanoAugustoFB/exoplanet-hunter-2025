# src/model_training.py
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.impute import SimpleImputer
import joblib
import os
from visualization import plot_confusion_matrix, plot_feature_importance, plot_label_distribution

# Caminhos relativos
BASE_PATH = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
DATA_PATH = os.path.join(BASE_PATH, 'PythonNasaAppChallenge_VoyIAger', 'cumulative_2025.10.03_20.29.09.csv')
MODEL_PATH = os.path.join(BASE_PATH, 'modelo_habitabilidade.pkl')
IMPUTER_PATH = os.path.join(BASE_PATH, 'imputer.pkl')
Y_TRUE_PATH = os.path.join(BASE_PATH, 'y_true.npy')
Y_PRED_PATH = os.path.join(BASE_PATH, 'y_pred.npy')
Y_LABELS_PATH = os.path.join(BASE_PATH, 'y_labels.npy')
FEATURE_IMPORTANCES_PATH = os.path.join(BASE_PATH, 'feature_importances.npy')

print("=" * 60)
print("ðŸš€ TREINAMENTO DE IA PARA EXOPLANETAS: HABITABILIDADE")
print("=" * 60)

# Verificar se o arquivo existe
if not os.path.exists(DATA_PATH):
    print(f"âŒ Erro: Arquivo nÃ£o encontrado em {DATA_PATH}")
    print("Dica: Liste os arquivos com 'ls PythonNasaAppChallenge_VoyIAger/' (Ubuntu) ou 'dir PythonNasaAppChallenge_VoyIAger\' (Windows)")
    exit(1)

# Carregar dados
print(f"ðŸ“‚ Carregando arquivo: {DATA_PATH}")
try:
    df = pd.read_csv(DATA_PATH, comment='#', skiprows=52, low_memory=False)
except Exception as e:
    print(f"âŒ Erro ao carregar CSV: {e}")
    exit(1)

# Filtrar planetas confirmados
confirmed_planets = df[df['koi_disposition'] == 'CONFIRMED'].copy()
print(f"ðŸª Planetas confirmados: {len(confirmed_planets)}")

# Selecionar features
features = ['koi_period', 'koi_prad', 'koi_teq', 'koi_insol']
if not all(col in df.columns for col in features):
    print(f"âŒ Erro: Colunas {features} nÃ£o encontradas no CSV. Colunas disponÃ­veis: {list(df.columns)}")
    exit(1)
X = confirmed_planets[features].copy()

# Tratar valores nulos
imputer = SimpleImputer(strategy='median')
X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=features, index=X.index)

# Criar label de habitabilidade
y = np.where(
    (confirmed_planets['koi_insol'].fillna(0) > 0.38) &
    (confirmed_planets['koi_insol'].fillna(0) < 1.1) &
    (X_imputed['koi_prad'] < 1.8), 1, 0
)
print(f"ðŸŽ¯ DistribuiÃ§Ã£o de labels: {np.bincount(y)} (0: NÃ£o HabitÃ¡vel, 1: HabitÃ¡vel)")

# Dividir dados
X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42, stratify=y)

# Treinar modelo com balanceamento
model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
model.fit(X_train, y_train)

# Avaliar
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"\nðŸ“Š AcurÃ¡cia do modelo: {accuracy:.2%}")
print("\nðŸ“ˆ RelatÃ³rio de classificaÃ§Ã£o:")
print(classification_report(y_test, y_pred, target_names=['NÃ£o HabitÃ¡vel', 'HabitÃ¡vel']))

# Gerar grÃ¡ficos
plot_confusion_matrix(y_test, y_pred)
plot_feature_importance(features, model.feature_importances_)
plot_label_distribution(y)

# Salvar dados para visualizaÃ§Ã£o
try:
    np.save(Y_TRUE_PATH, y_test)
    np.save(Y_PRED_PATH, y_pred)
    np.save(Y_LABELS_PATH, y)
    np.save(FEATURE_IMPORTANCES_PATH, model.feature_importances_)
    print(f"\nðŸ’¾ Dados de visualizaÃ§Ã£o salvos em:")
    print(f"  - {Y_TRUE_PATH}")
    print(f"  - {Y_PRED_PATH}")
    print(f"  - {Y_LABELS_PATH}")
    print(f"  - {FEATURE_IMPORTANCES_PATH}")
except Exception as e:
    print(f"âŒ Erro ao salvar arquivos .npy: {e}")
    exit(1)

# Salvar modelo e imputer
joblib.dump(model, MODEL_PATH)
joblib.dump(imputer, IMPUTER_PATH)
print(f"\nðŸ’¾ Modelo salvo em: {MODEL_PATH}")
print(f"ðŸ’¾ Imputer salvo em: {IMPUTER_PATH}")